{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8061506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fc136b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138359, 26), (138359, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(\"./data/processed/csp_bond_types.csv\", index_col=0)\n",
    "y = pd.read_csv(\"./data/processed/energy.csv\")\n",
    "\n",
    "non_nan_rows = (x.sum(axis=1)>0).to_list()\n",
    "\n",
    "x = x.loc[non_nan_rows].to_numpy()\n",
    "y = y.loc[non_nan_rows].to_numpy()\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb478f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c09d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((110687, 26), (110687, 1), (27672, 26), (27672, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db53fd",
   "metadata": {},
   "source": [
    "## Trianing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d261f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "work_dir = 'mansur/experiment_10'\n",
    "\n",
    "os.mkdir(f'{work_dir}')\n",
    "os.mkdir(f'{work_dir}/checkpoint')\n",
    "os.mkdir(f'{work_dir}/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f6fb831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 02:12:29.820342: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-25 02:12:29.820836: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense as d\n",
    "from tensorflow.keras.layers import InputLayer as i\n",
    "\n",
    "# idea for future\n",
    "# def neg_relu(x):\n",
    "#     return tf.nn.relu(x) * -1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    i(x.shape[1]),\n",
    "    d(100),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss=\"MSE\",\n",
    "    metrics=\"MAE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8334bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               2700      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,700\n",
      "Trainable params: 2,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514116e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 02:18:48.809090: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-06-25 02:18:48.997017: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - ETA: 0s - loss: 1553161.0000 - MAE: 1188.0322"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 02:18:59.955325: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 13s 4ms/step - loss: 1553161.0000 - MAE: 1188.0322 - val_loss: 1430784.5000 - val_MAE: 1132.3802\n",
      "Epoch 2/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 1296599.3750 - MAE: 1072.7427 - val_loss: 1189288.5000 - val_MAE: 1018.0193\n",
      "Epoch 3/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 1069623.5000 - MAE: 958.8203 - val_loss: 975879.8125 - val_MAE: 904.4897\n",
      "Epoch 4/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 870371.8125 - MAE: 845.6370 - val_loss: 789938.9375 - val_MAE: 791.7698\n",
      "Epoch 5/500\n",
      "2768/2768 [==============================] - 13s 5ms/step - loss: 698387.5625 - MAE: 733.3400 - val_loss: 631187.9375 - val_MAE: 680.0721\n",
      "Epoch 6/500\n",
      "2768/2768 [==============================] - 13s 5ms/step - loss: 553318.2500 - MAE: 622.2778 - val_loss: 499067.2500 - val_MAE: 569.5367\n",
      "Epoch 7/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 434998.5312 - MAE: 512.7819 - val_loss: 393528.5000 - val_MAE: 461.4135\n",
      "Epoch 8/500\n",
      "2768/2768 [==============================] - 13s 5ms/step - loss: 342813.1875 - MAE: 409.5878 - val_loss: 313900.0312 - val_MAE: 367.0732\n",
      "Epoch 9/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 276057.3438 - MAE: 332.5372 - val_loss: 259066.7656 - val_MAE: 311.4219\n",
      "Epoch 10/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 233184.0625 - MAE: 296.8989 - val_loss: 226928.2031 - val_MAE: 292.9811\n",
      "Epoch 11/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 210882.0625 - MAE: 287.5126 - val_loss: 212640.6094 - val_MAE: 289.3904\n",
      "Epoch 12/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 202052.8438 - MAE: 285.4828 - val_loss: 207124.4062 - val_MAE: 287.5337\n",
      "Epoch 13/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 197671.1875 - MAE: 282.8044 - val_loss: 203109.9531 - val_MAE: 284.0316\n",
      "Epoch 14/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 193896.1250 - MAE: 278.9641 - val_loss: 199385.2969 - val_MAE: 279.9122\n",
      "Epoch 15/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 190348.9844 - MAE: 274.8135 - val_loss: 195866.9062 - val_MAE: 275.7554\n",
      "Epoch 16/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 186978.8125 - MAE: 270.6096 - val_loss: 192527.6562 - val_MAE: 271.5857\n",
      "Epoch 17/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 183796.5000 - MAE: 266.4783 - val_loss: 189387.8438 - val_MAE: 267.4771\n",
      "Epoch 18/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 180779.5156 - MAE: 262.3756 - val_loss: 186397.6250 - val_MAE: 263.4805\n",
      "Epoch 19/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 177916.9062 - MAE: 258.4160 - val_loss: 183551.9688 - val_MAE: 259.4431\n",
      "Epoch 20/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 175159.0469 - MAE: 254.3891 - val_loss: 180796.5469 - val_MAE: 255.4765\n",
      "Epoch 21/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 172530.0156 - MAE: 250.5260 - val_loss: 178193.1250 - val_MAE: 251.4932\n",
      "Epoch 22/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 170017.8281 - MAE: 246.6703 - val_loss: 175701.5000 - val_MAE: 247.5535\n",
      "Epoch 23/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 167619.9062 - MAE: 242.7675 - val_loss: 173312.2188 - val_MAE: 243.8649\n",
      "Epoch 24/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 165329.3281 - MAE: 239.1427 - val_loss: 171036.4219 - val_MAE: 240.1313\n",
      "Epoch 25/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 163131.3281 - MAE: 235.4982 - val_loss: 168839.1094 - val_MAE: 236.3817\n",
      "Epoch 26/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 161018.5312 - MAE: 231.8509 - val_loss: 166738.0469 - val_MAE: 232.8016\n",
      "Epoch 27/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 158975.8281 - MAE: 228.2776 - val_loss: 164694.8281 - val_MAE: 229.2526\n",
      "Epoch 28/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 156999.5938 - MAE: 224.7922 - val_loss: 162719.3594 - val_MAE: 225.7468\n",
      "Epoch 29/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 155100.5469 - MAE: 221.3567 - val_loss: 160826.6406 - val_MAE: 222.3605\n",
      "Epoch 30/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 153274.4531 - MAE: 218.0439 - val_loss: 159006.5625 - val_MAE: 218.9374\n",
      "Epoch 31/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 151507.2031 - MAE: 214.7733 - val_loss: 157236.9375 - val_MAE: 215.6091\n",
      "Epoch 32/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 149805.5781 - MAE: 211.5072 - val_loss: 155542.6094 - val_MAE: 212.3659\n",
      "Epoch 33/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 148163.5156 - MAE: 208.3504 - val_loss: 153906.0156 - val_MAE: 209.2265\n",
      "Epoch 34/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 146589.0000 - MAE: 205.2553 - val_loss: 152330.3125 - val_MAE: 206.2408\n",
      "Epoch 35/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 145060.5781 - MAE: 202.1952 - val_loss: 150799.7500 - val_MAE: 203.4229\n",
      "Epoch 36/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 143599.5781 - MAE: 199.4553 - val_loss: 149342.9844 - val_MAE: 200.4433\n",
      "Epoch 37/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 142178.7188 - MAE: 196.5051 - val_loss: 147917.9844 - val_MAE: 197.6433\n",
      "Epoch 38/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 140808.1719 - MAE: 193.8840 - val_loss: 146552.5781 - val_MAE: 194.7309\n",
      "Epoch 39/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 139494.7344 - MAE: 191.1464 - val_loss: 145242.7188 - val_MAE: 192.0931\n",
      "Epoch 40/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 138219.6875 - MAE: 188.4396 - val_loss: 143963.9844 - val_MAE: 189.6725\n",
      "Epoch 41/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 136997.5625 - MAE: 186.0304 - val_loss: 142741.0312 - val_MAE: 187.1709\n",
      "Epoch 42/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 135811.8281 - MAE: 183.6773 - val_loss: 141549.4062 - val_MAE: 184.5233\n",
      "Epoch 43/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 134676.0156 - MAE: 181.2711 - val_loss: 140419.3594 - val_MAE: 182.2443\n",
      "Epoch 44/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 133578.6406 - MAE: 178.8429 - val_loss: 139317.6406 - val_MAE: 180.2345\n",
      "Epoch 45/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 132516.0000 - MAE: 176.8767 - val_loss: 138248.3594 - val_MAE: 177.7756\n",
      "Epoch 46/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 131485.4219 - MAE: 174.5265 - val_loss: 137220.4375 - val_MAE: 175.9452\n",
      "Epoch 47/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 130493.4531 - MAE: 172.6191 - val_loss: 136226.1250 - val_MAE: 173.8201\n",
      "Epoch 48/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 129535.5391 - MAE: 170.5909 - val_loss: 135268.1875 - val_MAE: 171.7356\n",
      "Epoch 49/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 128618.4141 - MAE: 168.8120 - val_loss: 134356.5469 - val_MAE: 169.3827\n",
      "Epoch 50/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 127725.1875 - MAE: 166.5427 - val_loss: 133452.1250 - val_MAE: 167.8476\n",
      "Epoch 51/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 126856.9297 - MAE: 164.7859 - val_loss: 132578.0625 - val_MAE: 166.1469\n",
      "Epoch 52/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 126020.0547 - MAE: 162.9837 - val_loss: 131743.3594 - val_MAE: 164.5173\n",
      "Epoch 53/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 125213.5391 - MAE: 161.4496 - val_loss: 130935.4844 - val_MAE: 162.4440\n",
      "Epoch 54/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 124429.2344 - MAE: 159.4135 - val_loss: 130146.1094 - val_MAE: 161.1001\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 12s 4ms/step - loss: 123677.2031 - MAE: 158.1413 - val_loss: 129396.1172 - val_MAE: 159.1306\n",
      "Epoch 56/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 122947.3828 - MAE: 156.2453 - val_loss: 128657.0000 - val_MAE: 157.7515\n",
      "Epoch 57/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 122232.9453 - MAE: 154.7499 - val_loss: 127941.5156 - val_MAE: 156.1885\n",
      "Epoch 58/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 121543.2656 - MAE: 153.2395 - val_loss: 127246.4219 - val_MAE: 154.7287\n",
      "Epoch 59/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 120872.4688 - MAE: 151.8907 - val_loss: 126574.3125 - val_MAE: 152.9947\n",
      "Epoch 60/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 120221.6406 - MAE: 150.1175 - val_loss: 125922.1094 - val_MAE: 151.9678\n",
      "Epoch 61/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 119595.1016 - MAE: 148.9207 - val_loss: 125289.4297 - val_MAE: 150.5146\n",
      "Epoch 62/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 118982.9609 - MAE: 147.7204 - val_loss: 124677.7422 - val_MAE: 148.6989\n",
      "Epoch 63/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 118388.3047 - MAE: 146.1761 - val_loss: 124077.4375 - val_MAE: 147.4661\n",
      "Epoch 64/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 117811.6797 - MAE: 144.7565 - val_loss: 123496.8281 - val_MAE: 146.3309\n",
      "Epoch 65/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 117245.4375 - MAE: 143.5179 - val_loss: 122927.7500 - val_MAE: 145.2421\n",
      "Epoch 66/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 116698.4688 - MAE: 142.4664 - val_loss: 122374.6797 - val_MAE: 143.7721\n",
      "Epoch 67/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 116160.6406 - MAE: 140.9975 - val_loss: 121836.1172 - val_MAE: 142.8137\n",
      "Epoch 68/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 115642.1484 - MAE: 140.0967 - val_loss: 121312.7344 - val_MAE: 141.1923\n",
      "Epoch 69/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 115131.9609 - MAE: 138.6310 - val_loss: 120795.4297 - val_MAE: 140.4460\n",
      "Epoch 70/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 114630.4453 - MAE: 137.6263 - val_loss: 120292.7344 - val_MAE: 139.2861\n",
      "Epoch 71/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 114144.1641 - MAE: 136.4180 - val_loss: 119805.7500 - val_MAE: 138.3959\n",
      "Epoch 72/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 113671.6797 - MAE: 135.6704 - val_loss: 119330.0938 - val_MAE: 136.7552\n",
      "Epoch 73/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 113205.3125 - MAE: 134.2650 - val_loss: 118855.5391 - val_MAE: 135.9690\n",
      "Epoch 74/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 112750.0547 - MAE: 133.2451 - val_loss: 118402.0391 - val_MAE: 135.1195\n",
      "Epoch 75/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 112305.6797 - MAE: 132.3511 - val_loss: 117952.1484 - val_MAE: 134.0282\n",
      "Epoch 76/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 111869.8516 - MAE: 131.4485 - val_loss: 117514.3516 - val_MAE: 132.7107\n",
      "Epoch 77/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 111441.0781 - MAE: 130.2465 - val_loss: 117081.2734 - val_MAE: 132.0307\n",
      "Epoch 78/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 111022.0000 - MAE: 129.4103 - val_loss: 116659.1953 - val_MAE: 131.1105\n",
      "Epoch 79/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 110610.4219 - MAE: 128.3949 - val_loss: 116245.3281 - val_MAE: 130.3621\n",
      "Epoch 80/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 110210.2188 - MAE: 127.5450 - val_loss: 115842.3750 - val_MAE: 129.4712\n",
      "Epoch 81/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 109815.4219 - MAE: 126.7787 - val_loss: 115443.9766 - val_MAE: 128.3577\n",
      "Epoch 82/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 109428.5078 - MAE: 125.7079 - val_loss: 115055.4062 - val_MAE: 127.7176\n",
      "Epoch 83/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 109048.8828 - MAE: 124.9544 - val_loss: 114674.6797 - val_MAE: 126.8523\n",
      "Epoch 84/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 108677.1562 - MAE: 124.1433 - val_loss: 114298.2891 - val_MAE: 126.1026\n",
      "Epoch 85/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 108310.6406 - MAE: 123.4627 - val_loss: 113931.7266 - val_MAE: 124.8930\n",
      "Epoch 86/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 107946.7266 - MAE: 122.3896 - val_loss: 113563.1328 - val_MAE: 124.3927\n",
      "Epoch 87/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 107591.0625 - MAE: 121.8823 - val_loss: 113207.7656 - val_MAE: 123.2548\n",
      "Epoch 88/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 107243.3203 - MAE: 120.7993 - val_loss: 112854.5859 - val_MAE: 122.8496\n",
      "Epoch 89/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 106897.2656 - MAE: 120.1716 - val_loss: 112506.5234 - val_MAE: 122.2308\n",
      "Epoch 90/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 106555.2188 - MAE: 119.6258 - val_loss: 112160.4531 - val_MAE: 121.1585\n",
      "Epoch 91/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 106218.2734 - MAE: 118.7092 - val_loss: 111823.5078 - val_MAE: 120.5159\n",
      "Epoch 92/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 105886.7578 - MAE: 118.0478 - val_loss: 111488.9141 - val_MAE: 119.7925\n",
      "Epoch 93/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 105558.1172 - MAE: 117.2454 - val_loss: 111156.1719 - val_MAE: 119.2613\n",
      "Epoch 94/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 105232.8125 - MAE: 116.4701 - val_loss: 110829.6875 - val_MAE: 118.9304\n",
      "Epoch 95/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 104914.2578 - MAE: 116.0063 - val_loss: 110509.3594 - val_MAE: 118.1081\n",
      "Epoch 96/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 104601.9141 - MAE: 115.3790 - val_loss: 110193.9844 - val_MAE: 117.1994\n",
      "Epoch 97/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 104290.0391 - MAE: 114.5662 - val_loss: 109878.3281 - val_MAE: 116.7085\n",
      "Epoch 98/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 103983.9844 - MAE: 114.0315 - val_loss: 109573.0312 - val_MAE: 115.9325\n",
      "Epoch 99/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 103677.9844 - MAE: 113.0785 - val_loss: 109265.4922 - val_MAE: 115.9240\n",
      "Epoch 100/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 103381.5547 - MAE: 112.8214 - val_loss: 108963.3438 - val_MAE: 114.9676\n",
      "Epoch 101/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 103086.6250 - MAE: 112.2281 - val_loss: 108666.9375 - val_MAE: 114.0220\n",
      "Epoch 102/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 102794.8906 - MAE: 111.4860 - val_loss: 108373.5547 - val_MAE: 113.4145\n",
      "Epoch 103/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 102504.3984 - MAE: 110.8849 - val_loss: 108079.4375 - val_MAE: 112.8161\n",
      "Epoch 104/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 102218.9688 - MAE: 110.4186 - val_loss: 107794.2969 - val_MAE: 111.9895\n",
      "Epoch 105/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 101936.7109 - MAE: 109.7146 - val_loss: 107508.7734 - val_MAE: 111.3180\n",
      "Epoch 106/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 101654.5938 - MAE: 108.9391 - val_loss: 107220.8906 - val_MAE: 111.3077\n",
      "Epoch 107/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 101375.0859 - MAE: 108.3879 - val_loss: 106939.8203 - val_MAE: 111.1801\n",
      "Epoch 108/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 101100.4141 - MAE: 108.3569 - val_loss: 106665.1328 - val_MAE: 109.7401\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 12s 4ms/step - loss: 100828.1797 - MAE: 107.3327 - val_loss: 106388.8906 - val_MAE: 109.4787\n",
      "Epoch 110/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 100560.9297 - MAE: 106.9766 - val_loss: 106122.0547 - val_MAE: 108.6331\n",
      "Epoch 111/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 100295.6484 - MAE: 106.2416 - val_loss: 105852.0703 - val_MAE: 108.5535\n",
      "Epoch 112/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 100034.5000 - MAE: 105.8090 - val_loss: 105587.8125 - val_MAE: 108.0660\n",
      "Epoch 113/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 99775.7188 - MAE: 105.4155 - val_loss: 105327.4453 - val_MAE: 107.3868\n",
      "Epoch 114/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 99517.8672 - MAE: 104.6766 - val_loss: 105065.0625 - val_MAE: 107.1991\n",
      "Epoch 115/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 99261.2812 - MAE: 104.2932 - val_loss: 104806.6328 - val_MAE: 106.7098\n",
      "Epoch 116/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 99008.3359 - MAE: 103.8523 - val_loss: 104551.5234 - val_MAE: 106.0552\n",
      "Epoch 117/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 98759.9297 - MAE: 103.2636 - val_loss: 104301.2031 - val_MAE: 105.6489\n",
      "Epoch 118/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 98515.0312 - MAE: 102.9741 - val_loss: 104054.9922 - val_MAE: 104.6322\n",
      "Epoch 119/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 98269.6641 - MAE: 102.1897 - val_loss: 103804.5938 - val_MAE: 104.4778\n",
      "Epoch 120/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 98027.2812 - MAE: 101.8883 - val_loss: 103560.7656 - val_MAE: 103.7962\n",
      "Epoch 121/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 97783.6641 - MAE: 101.1490 - val_loss: 103310.9219 - val_MAE: 103.8684\n",
      "Epoch 122/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 97541.6016 - MAE: 100.6964 - val_loss: 103068.7422 - val_MAE: 103.7613\n",
      "Epoch 123/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 97304.3906 - MAE: 100.4909 - val_loss: 102825.5078 - val_MAE: 102.9467\n",
      "Epoch 124/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 97068.2578 - MAE: 100.0686 - val_loss: 102588.4141 - val_MAE: 102.0416\n",
      "Epoch 125/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 96833.8906 - MAE: 99.3738 - val_loss: 102349.6328 - val_MAE: 101.8487\n",
      "Epoch 126/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 96604.6172 - MAE: 99.1271 - val_loss: 102120.4375 - val_MAE: 100.9294\n",
      "Epoch 127/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 96373.7891 - MAE: 98.3595 - val_loss: 101883.8047 - val_MAE: 101.0438\n",
      "Epoch 128/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 96144.8203 - MAE: 98.0231 - val_loss: 101651.8125 - val_MAE: 100.7191\n",
      "Epoch 129/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 95919.1016 - MAE: 97.7702 - val_loss: 101422.8984 - val_MAE: 99.8237\n",
      "Epoch 130/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 95694.9219 - MAE: 97.2644 - val_loss: 101196.4844 - val_MAE: 99.1728\n",
      "Epoch 131/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 95472.3516 - MAE: 96.6596 - val_loss: 100970.2969 - val_MAE: 98.9257\n",
      "Epoch 132/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 95252.9219 - MAE: 96.2822 - val_loss: 100745.4531 - val_MAE: 98.5035\n",
      "Epoch 133/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 95032.1406 - MAE: 96.1424 - val_loss: 100527.0938 - val_MAE: 97.3818\n",
      "Epoch 134/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 94816.9609 - MAE: 95.3163 - val_loss: 100305.8047 - val_MAE: 97.1618\n",
      "Epoch 135/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 94601.4609 - MAE: 94.9011 - val_loss: 100085.0156 - val_MAE: 97.0217\n",
      "Epoch 136/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 94386.1016 - MAE: 94.3704 - val_loss: 99866.4844 - val_MAE: 97.0240\n",
      "Epoch 137/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 94176.2969 - MAE: 94.1205 - val_loss: 99652.1484 - val_MAE: 96.8127\n",
      "Epoch 138/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 93969.0781 - MAE: 93.9567 - val_loss: 99444.3125 - val_MAE: 95.8116\n",
      "Epoch 139/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 93760.9297 - MAE: 93.3195 - val_loss: 99228.2344 - val_MAE: 95.4197\n",
      "Epoch 140/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 93552.5234 - MAE: 92.8826 - val_loss: 99019.1250 - val_MAE: 95.0306\n",
      "Epoch 141/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 93346.3359 - MAE: 92.3648 - val_loss: 98806.1250 - val_MAE: 94.9585\n",
      "Epoch 142/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 93140.0391 - MAE: 92.0385 - val_loss: 98597.4688 - val_MAE: 94.5798\n",
      "Epoch 143/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 92939.9531 - MAE: 91.9091 - val_loss: 98395.6719 - val_MAE: 93.4925\n",
      "Epoch 144/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 92738.3281 - MAE: 91.1484 - val_loss: 98188.2031 - val_MAE: 93.4524\n",
      "Epoch 145/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 92538.1641 - MAE: 90.9714 - val_loss: 97985.3828 - val_MAE: 92.7966\n",
      "Epoch 146/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 92343.0547 - MAE: 90.4258 - val_loss: 97785.7578 - val_MAE: 92.3459\n",
      "Epoch 147/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 92146.7656 - MAE: 90.2017 - val_loss: 97589.1641 - val_MAE: 91.5904\n",
      "Epoch 148/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 91954.0703 - MAE: 89.3986 - val_loss: 97387.3281 - val_MAE: 91.8673\n",
      "Epoch 149/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 91761.1953 - MAE: 89.2310 - val_loss: 97191.2969 - val_MAE: 91.4596\n",
      "Epoch 150/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 91569.0234 - MAE: 88.8204 - val_loss: 96992.6875 - val_MAE: 91.1844\n",
      "Epoch 151/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 91378.2891 - MAE: 88.5643 - val_loss: 96798.8672 - val_MAE: 90.6858\n",
      "Epoch 152/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 91188.6641 - MAE: 87.9034 - val_loss: 96602.6172 - val_MAE: 90.7857\n",
      "Epoch 153/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 90999.9141 - MAE: 87.8066 - val_loss: 96410.2891 - val_MAE: 90.0360\n",
      "Epoch 154/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 90814.1562 - MAE: 87.2173 - val_loss: 96220.8672 - val_MAE: 90.0294\n",
      "Epoch 155/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 90631.0703 - MAE: 87.1615 - val_loss: 96035.5234 - val_MAE: 89.0854\n",
      "Epoch 156/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 90450.1719 - MAE: 86.5385 - val_loss: 95848.5078 - val_MAE: 88.8227\n",
      "Epoch 157/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 90268.5234 - MAE: 86.2395 - val_loss: 95661.8047 - val_MAE: 88.3416\n",
      "Epoch 158/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 90086.1562 - MAE: 85.9032 - val_loss: 95475.6953 - val_MAE: 87.7076\n",
      "Epoch 159/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 89905.5234 - MAE: 85.2638 - val_loss: 95288.4141 - val_MAE: 87.9728\n",
      "Epoch 160/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 89729.5000 - MAE: 85.1459 - val_loss: 95107.8438 - val_MAE: 87.4513\n",
      "Epoch 161/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 89553.8203 - MAE: 84.7217 - val_loss: 94926.2578 - val_MAE: 87.1512\n",
      "Epoch 162/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 89378.2656 - MAE: 84.4431 - val_loss: 94747.2266 - val_MAE: 86.6615\n",
      "Epoch 163/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 89203.6875 - MAE: 83.9475 - val_loss: 94565.9375 - val_MAE: 86.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 89029.4219 - MAE: 83.9738 - val_loss: 94393.1172 - val_MAE: 85.3667\n",
      "Epoch 165/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 88857.8125 - MAE: 83.2060 - val_loss: 94210.4062 - val_MAE: 85.5437\n",
      "Epoch 166/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 88688.0234 - MAE: 82.9866 - val_loss: 94036.1094 - val_MAE: 85.3930\n",
      "Epoch 167/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 88519.1953 - MAE: 82.6035 - val_loss: 93860.9922 - val_MAE: 85.1679\n",
      "Epoch 168/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 88348.5781 - MAE: 82.2364 - val_loss: 93684.4141 - val_MAE: 84.9398\n",
      "Epoch 169/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 88181.0312 - MAE: 81.9143 - val_loss: 93512.2734 - val_MAE: 84.6995\n",
      "Epoch 170/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 88015.2734 - MAE: 81.7469 - val_loss: 93341.1406 - val_MAE: 84.0911\n",
      "Epoch 171/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 87851.4688 - MAE: 81.5948 - val_loss: 93179.2188 - val_MAE: 82.9784\n",
      "Epoch 172/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 87688.3438 - MAE: 80.8332 - val_loss: 93003.6641 - val_MAE: 82.9948\n",
      "Epoch 173/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 87523.6016 - MAE: 80.5762 - val_loss: 92833.5469 - val_MAE: 82.7623\n",
      "Epoch 174/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 87360.5156 - MAE: 80.4263 - val_loss: 92667.6875 - val_MAE: 82.2432\n",
      "Epoch 175/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 87200.6875 - MAE: 79.7545 - val_loss: 92498.2500 - val_MAE: 82.6011\n",
      "Epoch 176/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 87041.1406 - MAE: 79.7764 - val_loss: 92335.2109 - val_MAE: 82.0495\n",
      "Epoch 177/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 86884.1953 - MAE: 79.3835 - val_loss: 92171.1484 - val_MAE: 81.7034\n",
      "Epoch 178/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 86726.3906 - MAE: 79.0747 - val_loss: 92008.4688 - val_MAE: 81.5495\n",
      "Epoch 179/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 86573.5234 - MAE: 78.7213 - val_loss: 91848.8516 - val_MAE: 81.5463\n",
      "Epoch 180/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 86419.7344 - MAE: 78.4435 - val_loss: 91688.1328 - val_MAE: 81.3817\n",
      "Epoch 181/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 86266.7891 - MAE: 78.3874 - val_loss: 91531.5234 - val_MAE: 80.5095\n",
      "Epoch 182/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 86112.5859 - MAE: 77.9216 - val_loss: 91370.4531 - val_MAE: 80.3801\n",
      "Epoch 183/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 85959.7578 - MAE: 77.7949 - val_loss: 91214.1172 - val_MAE: 79.6352\n",
      "Epoch 184/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 85806.8672 - MAE: 77.1751 - val_loss: 91053.4062 - val_MAE: 79.8002\n",
      "Epoch 185/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 85656.6094 - MAE: 77.0193 - val_loss: 90895.9688 - val_MAE: 79.6743\n",
      "Epoch 186/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 85508.0703 - MAE: 77.0173 - val_loss: 90744.1250 - val_MAE: 78.8162\n",
      "Epoch 187/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 85359.6094 - MAE: 76.5578 - val_loss: 90590.3203 - val_MAE: 78.3899\n",
      "Epoch 188/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 85210.7031 - MAE: 76.1877 - val_loss: 90432.0547 - val_MAE: 78.3955\n",
      "Epoch 189/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 85062.2422 - MAE: 75.8197 - val_loss: 90275.2656 - val_MAE: 78.6051\n",
      "Epoch 190/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 84913.7812 - MAE: 75.6237 - val_loss: 90121.1406 - val_MAE: 78.6665\n",
      "Epoch 191/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 84770.3125 - MAE: 75.6953 - val_loss: 89972.6172 - val_MAE: 77.7738\n",
      "Epoch 192/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 84625.0859 - MAE: 75.2650 - val_loss: 89822.1875 - val_MAE: 77.4764\n",
      "Epoch 193/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 84481.2500 - MAE: 74.9391 - val_loss: 89669.0625 - val_MAE: 77.4215\n",
      "Epoch 194/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 84337.0391 - MAE: 74.6854 - val_loss: 89518.6719 - val_MAE: 77.3891\n",
      "Epoch 195/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 84194.1172 - MAE: 74.5330 - val_loss: 89370.4297 - val_MAE: 77.0580\n",
      "Epoch 196/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 84055.0625 - MAE: 74.4016 - val_loss: 89226.3438 - val_MAE: 76.6049\n",
      "Epoch 197/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 83916.2734 - MAE: 74.0475 - val_loss: 89079.7109 - val_MAE: 76.3895\n",
      "Epoch 198/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 83776.1484 - MAE: 73.8882 - val_loss: 88932.9766 - val_MAE: 76.3510\n",
      "Epoch 199/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 83636.9688 - MAE: 73.5765 - val_loss: 88784.5547 - val_MAE: 76.3047\n",
      "Epoch 200/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 83498.0312 - MAE: 73.5492 - val_loss: 88642.9141 - val_MAE: 75.8273\n",
      "Epoch 201/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 83361.5469 - MAE: 73.1059 - val_loss: 88495.9766 - val_MAE: 75.9850\n",
      "Epoch 202/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 83223.6328 - MAE: 73.0629 - val_loss: 88351.9375 - val_MAE: 75.7044\n",
      "Epoch 203/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 83085.8594 - MAE: 72.6785 - val_loss: 88206.7031 - val_MAE: 75.8622\n",
      "Epoch 204/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 82949.9453 - MAE: 72.6334 - val_loss: 88063.7734 - val_MAE: 75.5806\n",
      "Epoch 205/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 82813.7109 - MAE: 72.4905 - val_loss: 87920.4062 - val_MAE: 75.3084\n",
      "Epoch 206/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 82680.1094 - MAE: 72.3335 - val_loss: 87781.7812 - val_MAE: 74.8426\n",
      "Epoch 207/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 82545.2891 - MAE: 72.0970 - val_loss: 87640.0312 - val_MAE: 74.5991\n",
      "Epoch 208/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 82411.9375 - MAE: 71.9341 - val_loss: 87500.7109 - val_MAE: 74.3680\n",
      "Epoch 209/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 82278.9453 - MAE: 71.9113 - val_loss: 87364.0469 - val_MAE: 73.7210\n",
      "Epoch 210/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 82147.0156 - MAE: 71.4250 - val_loss: 87220.5859 - val_MAE: 73.9538\n",
      "Epoch 211/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 82013.6172 - MAE: 71.4554 - val_loss: 87081.6094 - val_MAE: 73.7041\n",
      "Epoch 212/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 81882.1719 - MAE: 71.3111 - val_loss: 86944.1406 - val_MAE: 73.4561\n",
      "Epoch 213/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 81751.4688 - MAE: 70.8488 - val_loss: 86803.5781 - val_MAE: 73.9136\n",
      "Epoch 214/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 81620.0781 - MAE: 71.0342 - val_loss: 86663.6016 - val_MAE: 73.5872\n",
      "Epoch 215/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 81487.9844 - MAE: 70.8612 - val_loss: 86525.1094 - val_MAE: 73.4772\n",
      "Epoch 216/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 81357.8984 - MAE: 70.6073 - val_loss: 86387.9141 - val_MAE: 73.4637\n",
      "Epoch 217/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 81225.8984 - MAE: 70.3959 - val_loss: 86249.3203 - val_MAE: 73.7444\n",
      "Epoch 218/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 81099.1172 - MAE: 70.6980 - val_loss: 86118.4141 - val_MAE: 72.6591\n",
      "Epoch 219/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 12s 4ms/step - loss: 80969.6875 - MAE: 70.0842 - val_loss: 85978.5234 - val_MAE: 73.0300\n",
      "Epoch 220/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 80843.5391 - MAE: 70.2722 - val_loss: 85847.6172 - val_MAE: 72.6465\n",
      "Epoch 221/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 80715.9297 - MAE: 69.9066 - val_loss: 85710.1484 - val_MAE: 72.7981\n",
      "Epoch 222/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 80588.5781 - MAE: 69.9758 - val_loss: 85577.2734 - val_MAE: 72.3603\n",
      "Epoch 223/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 80462.0547 - MAE: 69.8646 - val_loss: 85445.6719 - val_MAE: 71.9334\n",
      "Epoch 224/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 80334.2109 - MAE: 69.6001 - val_loss: 85308.3672 - val_MAE: 71.9844\n",
      "Epoch 225/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 80206.5078 - MAE: 69.4597 - val_loss: 85175.0078 - val_MAE: 71.9874\n",
      "Epoch 226/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 80079.5000 - MAE: 69.4371 - val_loss: 85037.7109 - val_MAE: 71.9778\n",
      "Epoch 227/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 79952.4922 - MAE: 69.5636 - val_loss: 84909.4609 - val_MAE: 71.3368\n",
      "Epoch 228/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 79828.4609 - MAE: 68.9819 - val_loss: 84772.4141 - val_MAE: 71.8390\n",
      "Epoch 229/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 79702.8672 - MAE: 69.2194 - val_loss: 84641.7578 - val_MAE: 71.4698\n",
      "Epoch 230/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 79578.5703 - MAE: 69.0276 - val_loss: 84510.3906 - val_MAE: 71.2617\n",
      "Epoch 231/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 79453.3047 - MAE: 68.8056 - val_loss: 84375.4297 - val_MAE: 71.4225\n",
      "Epoch 232/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 79328.3750 - MAE: 68.9161 - val_loss: 84245.5156 - val_MAE: 71.0596\n",
      "Epoch 233/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 79203.8672 - MAE: 68.6512 - val_loss: 84112.3750 - val_MAE: 71.3488\n",
      "Epoch 234/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 79079.3203 - MAE: 68.5399 - val_loss: 83978.0078 - val_MAE: 71.4866\n",
      "Epoch 235/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 78954.9609 - MAE: 68.6236 - val_loss: 83846.8516 - val_MAE: 71.1373\n",
      "Epoch 236/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 78829.0234 - MAE: 68.4276 - val_loss: 83714.3359 - val_MAE: 71.0238\n",
      "Epoch 237/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 78707.1641 - MAE: 68.4300 - val_loss: 83587.9375 - val_MAE: 70.6930\n",
      "Epoch 238/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 78583.9609 - MAE: 68.0953 - val_loss: 83453.9219 - val_MAE: 71.0485\n",
      "Epoch 239/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 78459.4062 - MAE: 68.3213 - val_loss: 83322.3047 - val_MAE: 70.6272\n",
      "Epoch 240/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 78334.7188 - MAE: 68.0183 - val_loss: 83191.3203 - val_MAE: 70.7646\n",
      "Epoch 241/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 78212.9219 - MAE: 68.1813 - val_loss: 83064.6328 - val_MAE: 70.1434\n",
      "Epoch 242/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 78091.0703 - MAE: 67.8772 - val_loss: 82933.7891 - val_MAE: 70.3333\n",
      "Epoch 243/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 77967.7188 - MAE: 67.9917 - val_loss: 82804.6328 - val_MAE: 69.8574\n",
      "Epoch 244/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 77845.2500 - MAE: 67.8186 - val_loss: 82675.9219 - val_MAE: 69.7083\n",
      "Epoch 245/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 77720.9922 - MAE: 67.3637 - val_loss: 82539.3203 - val_MAE: 70.5643\n",
      "Epoch 246/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 77599.5312 - MAE: 67.7842 - val_loss: 82412.2344 - val_MAE: 70.0323\n",
      "Epoch 247/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 77478.6250 - MAE: 67.6457 - val_loss: 82285.5703 - val_MAE: 69.7010\n",
      "Epoch 248/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 77357.3906 - MAE: 67.3615 - val_loss: 82153.7734 - val_MAE: 70.0162\n",
      "Epoch 249/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 77236.2656 - MAE: 67.6137 - val_loss: 82029.9609 - val_MAE: 69.3798\n",
      "Epoch 250/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 77115.3359 - MAE: 67.2634 - val_loss: 81899.2344 - val_MAE: 69.4742\n",
      "Epoch 251/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 76992.7891 - MAE: 67.6511 - val_loss: 81781.8438 - val_MAE: 68.4854\n",
      "Epoch 252/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 76874.5312 - MAE: 66.8342 - val_loss: 81643.0078 - val_MAE: 69.5161\n",
      "Epoch 253/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 76754.4688 - MAE: 67.2891 - val_loss: 81519.6484 - val_MAE: 69.0187\n",
      "Epoch 254/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 76635.8281 - MAE: 67.0303 - val_loss: 81392.6016 - val_MAE: 69.0722\n",
      "Epoch 255/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 76516.4062 - MAE: 66.8328 - val_loss: 81261.6562 - val_MAE: 69.4825\n",
      "Epoch 256/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 76395.0625 - MAE: 67.0681 - val_loss: 81135.1484 - val_MAE: 69.0343\n",
      "Epoch 257/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 76275.1016 - MAE: 66.8999 - val_loss: 81007.5781 - val_MAE: 69.0080\n",
      "Epoch 258/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 76153.6719 - MAE: 66.9481 - val_loss: 80882.6094 - val_MAE: 68.5836\n",
      "Epoch 259/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 76034.1250 - MAE: 66.4964 - val_loss: 80749.6172 - val_MAE: 69.5699\n",
      "Epoch 260/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 75916.0859 - MAE: 66.8030 - val_loss: 80624.0234 - val_MAE: 69.2699\n",
      "Epoch 261/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 75797.3359 - MAE: 66.8238 - val_loss: 80501.1328 - val_MAE: 68.7103\n",
      "Epoch 262/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 75677.9531 - MAE: 66.5575 - val_loss: 80373.4219 - val_MAE: 68.6439\n",
      "Epoch 263/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 75557.4844 - MAE: 66.4846 - val_loss: 80245.2578 - val_MAE: 68.8163\n",
      "Epoch 264/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 75436.8516 - MAE: 66.6740 - val_loss: 80121.9062 - val_MAE: 68.1719\n",
      "Epoch 265/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 75316.8672 - MAE: 66.0758 - val_loss: 79986.1797 - val_MAE: 69.1738\n",
      "Epoch 266/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 75197.7422 - MAE: 66.4470 - val_loss: 79861.0000 - val_MAE: 68.8501\n",
      "Epoch 267/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 75078.7266 - MAE: 66.3916 - val_loss: 79737.6094 - val_MAE: 68.4079\n",
      "Epoch 268/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 74958.2578 - MAE: 65.9939 - val_loss: 79605.9766 - val_MAE: 69.2111\n",
      "Epoch 269/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 74841.3125 - MAE: 66.5523 - val_loss: 79487.1562 - val_MAE: 68.1217\n",
      "Epoch 270/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 74721.7500 - MAE: 65.9169 - val_loss: 79354.3203 - val_MAE: 68.8327\n",
      "Epoch 271/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 74602.3750 - MAE: 66.1348 - val_loss: 79229.6562 - val_MAE: 68.4616\n",
      "Epoch 272/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 74484.2422 - MAE: 66.0376 - val_loss: 79103.7188 - val_MAE: 68.4403\n",
      "Epoch 273/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 74366.3281 - MAE: 65.9552 - val_loss: 78978.4922 - val_MAE: 68.5678\n",
      "Epoch 274/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 12s 4ms/step - loss: 74249.9688 - MAE: 66.2587 - val_loss: 78862.7266 - val_MAE: 67.5919\n",
      "Epoch 275/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 74132.8203 - MAE: 65.6171 - val_loss: 78730.1016 - val_MAE: 68.3967\n",
      "Epoch 276/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 74015.1875 - MAE: 65.8857 - val_loss: 78606.9531 - val_MAE: 68.1829\n",
      "Epoch 277/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 73899.4062 - MAE: 65.8342 - val_loss: 78484.0000 - val_MAE: 67.8984\n",
      "Epoch 278/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 73781.2266 - MAE: 65.7053 - val_loss: 78357.8984 - val_MAE: 67.8173\n",
      "Epoch 279/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 73662.2969 - MAE: 65.6449 - val_loss: 78230.2578 - val_MAE: 67.9020\n",
      "Epoch 280/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 73544.8516 - MAE: 65.6868 - val_loss: 78108.4062 - val_MAE: 67.6540\n",
      "Epoch 281/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 73428.6406 - MAE: 65.6099 - val_loss: 77984.1328 - val_MAE: 67.5587\n",
      "Epoch 282/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 73310.1406 - MAE: 65.4571 - val_loss: 77857.0625 - val_MAE: 67.6447\n",
      "Epoch 283/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 73192.3438 - MAE: 65.5329 - val_loss: 77733.6406 - val_MAE: 67.4621\n",
      "Epoch 284/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 73073.7344 - MAE: 65.1936 - val_loss: 77603.5469 - val_MAE: 68.0699\n",
      "Epoch 285/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 72955.4531 - MAE: 65.3620 - val_loss: 77479.4453 - val_MAE: 68.0124\n",
      "Epoch 286/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 72840.8203 - MAE: 65.4290 - val_loss: 77360.0391 - val_MAE: 67.5416\n",
      "Epoch 287/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 72726.5000 - MAE: 65.3446 - val_loss: 77237.4297 - val_MAE: 67.4455\n",
      "Epoch 288/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 72610.5312 - MAE: 65.1622 - val_loss: 77114.3281 - val_MAE: 67.4331\n",
      "Epoch 289/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 72495.5625 - MAE: 65.1984 - val_loss: 76991.5625 - val_MAE: 67.3128\n",
      "Epoch 290/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 72378.6094 - MAE: 65.1657 - val_loss: 76868.6875 - val_MAE: 67.2059\n",
      "Epoch 291/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 72262.6406 - MAE: 65.2283 - val_loss: 76748.7188 - val_MAE: 66.7702\n",
      "Epoch 292/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 72148.3672 - MAE: 64.8792 - val_loss: 76622.8359 - val_MAE: 67.3813\n",
      "Epoch 293/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 72032.0469 - MAE: 64.9067 - val_loss: 76497.2969 - val_MAE: 67.5051\n",
      "Epoch 294/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 71916.8438 - MAE: 65.0689 - val_loss: 76377.9844 - val_MAE: 67.0576\n",
      "Epoch 295/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 71801.9453 - MAE: 64.8347 - val_loss: 76254.5078 - val_MAE: 67.1838\n",
      "Epoch 296/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 71686.9297 - MAE: 65.1110 - val_loss: 76137.9766 - val_MAE: 66.4298\n",
      "Epoch 297/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 71572.6562 - MAE: 64.5654 - val_loss: 76010.7656 - val_MAE: 67.0710\n",
      "Epoch 298/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 71457.9531 - MAE: 64.9243 - val_loss: 75891.3828 - val_MAE: 66.6046\n",
      "Epoch 299/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 71343.1016 - MAE: 64.5852 - val_loss: 75765.1875 - val_MAE: 66.9889\n",
      "Epoch 300/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 71226.8281 - MAE: 64.6033 - val_loss: 75641.2734 - val_MAE: 67.0918\n",
      "Epoch 301/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 71111.9062 - MAE: 64.6986 - val_loss: 75520.4219 - val_MAE: 66.9135\n",
      "Epoch 302/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 70997.0156 - MAE: 64.6425 - val_loss: 75399.9609 - val_MAE: 66.6768\n",
      "Epoch 303/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 70881.2969 - MAE: 64.5030 - val_loss: 75274.1016 - val_MAE: 66.8813\n",
      "Epoch 304/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 70766.6172 - MAE: 64.7073 - val_loss: 75159.2188 - val_MAE: 66.1492\n",
      "Epoch 305/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 70650.8906 - MAE: 64.1679 - val_loss: 75029.8281 - val_MAE: 66.9881\n",
      "Epoch 306/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 70536.4219 - MAE: 64.3378 - val_loss: 74906.9062 - val_MAE: 67.2480\n",
      "Epoch 307/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 70423.6016 - MAE: 64.6147 - val_loss: 74790.4922 - val_MAE: 66.4114\n",
      "Epoch 308/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 70310.7578 - MAE: 64.1960 - val_loss: 74668.6328 - val_MAE: 66.6991\n",
      "Epoch 309/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 70196.3984 - MAE: 64.3090 - val_loss: 74546.2578 - val_MAE: 66.6798\n",
      "Epoch 310/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 70081.3125 - MAE: 64.0901 - val_loss: 74422.4766 - val_MAE: 67.0544\n",
      "Epoch 311/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 69967.5625 - MAE: 64.4340 - val_loss: 74306.5625 - val_MAE: 66.1927\n",
      "Epoch 312/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 69853.7578 - MAE: 64.0009 - val_loss: 74180.8906 - val_MAE: 66.6442\n",
      "Epoch 313/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 69738.3672 - MAE: 64.0993 - val_loss: 74059.5469 - val_MAE: 66.5737\n",
      "Epoch 314/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 69625.6641 - MAE: 64.3017 - val_loss: 73944.8125 - val_MAE: 65.7683\n",
      "Epoch 315/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 69511.3906 - MAE: 63.7911 - val_loss: 73817.6875 - val_MAE: 66.4177\n",
      "Epoch 316/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 69397.5703 - MAE: 64.0183 - val_loss: 73698.7422 - val_MAE: 66.1918\n",
      "Epoch 317/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 69284.8047 - MAE: 63.8000 - val_loss: 73576.6406 - val_MAE: 66.5585\n",
      "Epoch 318/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 69171.5859 - MAE: 64.1367 - val_loss: 73459.2656 - val_MAE: 65.8613\n",
      "Epoch 319/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 69058.1328 - MAE: 63.8291 - val_loss: 73338.5078 - val_MAE: 65.8602\n",
      "Epoch 320/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 68946.2188 - MAE: 63.7446 - val_loss: 73217.7344 - val_MAE: 66.0196\n",
      "Epoch 321/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 68830.7109 - MAE: 63.5652 - val_loss: 73092.6719 - val_MAE: 66.4688\n",
      "Epoch 322/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 68718.7188 - MAE: 64.0609 - val_loss: 72980.4844 - val_MAE: 65.4776\n",
      "Epoch 323/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 68605.5312 - MAE: 63.8038 - val_loss: 72860.8281 - val_MAE: 65.2061\n",
      "Epoch 324/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 68492.8516 - MAE: 63.3294 - val_loss: 72734.1484 - val_MAE: 66.0226\n",
      "Epoch 325/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 68379.3125 - MAE: 63.8512 - val_loss: 72620.5703 - val_MAE: 65.2068\n",
      "Epoch 326/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 68266.0391 - MAE: 63.3355 - val_loss: 72492.2500 - val_MAE: 65.9383\n",
      "Epoch 327/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 68153.3047 - MAE: 63.5828 - val_loss: 72376.3047 - val_MAE: 65.5024\n",
      "Epoch 328/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 68041.2969 - MAE: 63.4564 - val_loss: 72255.9844 - val_MAE: 65.7224\n",
      "Epoch 329/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 12s 4ms/step - loss: 67929.4297 - MAE: 63.3673 - val_loss: 72135.6094 - val_MAE: 65.8923\n",
      "Epoch 330/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 67817.9219 - MAE: 63.3824 - val_loss: 72017.7734 - val_MAE: 65.8379\n",
      "Epoch 331/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 67707.9531 - MAE: 63.4812 - val_loss: 71902.4609 - val_MAE: 65.5781\n",
      "Epoch 332/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 67595.0156 - MAE: 63.0903 - val_loss: 71778.9062 - val_MAE: 66.2770\n",
      "Epoch 333/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 67481.8984 - MAE: 63.6143 - val_loss: 71663.3125 - val_MAE: 65.1211\n",
      "Epoch 334/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 67370.8281 - MAE: 63.1202 - val_loss: 71542.4141 - val_MAE: 65.4217\n",
      "Epoch 335/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 67258.3438 - MAE: 63.3626 - val_loss: 71426.6797 - val_MAE: 64.9331\n",
      "Epoch 336/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 67145.6953 - MAE: 62.9277 - val_loss: 71302.3438 - val_MAE: 65.4679\n",
      "Epoch 337/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 67035.0391 - MAE: 63.2884 - val_loss: 71188.0391 - val_MAE: 65.0499\n",
      "Epoch 338/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 66923.8203 - MAE: 63.0360 - val_loss: 71068.4062 - val_MAE: 65.1106\n",
      "Epoch 339/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 66810.4688 - MAE: 62.6781 - val_loss: 70946.2109 - val_MAE: 66.1531\n",
      "Epoch 340/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 66701.8594 - MAE: 63.3912 - val_loss: 70832.5703 - val_MAE: 65.0209\n",
      "Epoch 341/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 66591.5391 - MAE: 63.0281 - val_loss: 70716.3516 - val_MAE: 64.6793\n",
      "Epoch 342/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 66478.4219 - MAE: 62.6400 - val_loss: 70592.5312 - val_MAE: 65.5108\n",
      "Epoch 343/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 66367.9766 - MAE: 62.9477 - val_loss: 70476.7656 - val_MAE: 65.1057\n",
      "Epoch 344/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 66257.6094 - MAE: 62.8304 - val_loss: 70358.8984 - val_MAE: 65.0985\n",
      "Epoch 345/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 66146.7188 - MAE: 62.8798 - val_loss: 70241.3984 - val_MAE: 64.7877\n",
      "Epoch 346/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 66035.1719 - MAE: 62.8946 - val_loss: 70126.0547 - val_MAE: 64.3792\n",
      "Epoch 347/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 65924.5625 - MAE: 62.5197 - val_loss: 70004.1094 - val_MAE: 64.9011\n",
      "Epoch 348/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 65813.8516 - MAE: 62.6725 - val_loss: 69887.8984 - val_MAE: 64.7047\n",
      "Epoch 349/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 65701.7188 - MAE: 62.5221 - val_loss: 69766.8984 - val_MAE: 64.9866\n",
      "Epoch 350/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 65591.5000 - MAE: 62.7040 - val_loss: 69652.0938 - val_MAE: 64.5718\n",
      "Epoch 351/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 65481.7461 - MAE: 62.6006 - val_loss: 69536.3906 - val_MAE: 64.4272\n",
      "Epoch 352/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 65372.5547 - MAE: 62.5038 - val_loss: 69420.6562 - val_MAE: 64.2870\n",
      "Epoch 353/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 65262.7695 - MAE: 62.5285 - val_loss: 69305.3672 - val_MAE: 64.0636\n",
      "Epoch 354/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 65153.2188 - MAE: 62.2894 - val_loss: 69184.6875 - val_MAE: 64.5446\n",
      "Epoch 355/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 65044.1602 - MAE: 62.4249 - val_loss: 69071.0938 - val_MAE: 64.2601\n",
      "Epoch 356/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 64936.3008 - MAE: 62.2458 - val_loss: 68954.2578 - val_MAE: 64.5244\n",
      "Epoch 357/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 64828.1836 - MAE: 62.3607 - val_loss: 68840.9062 - val_MAE: 64.3408\n",
      "Epoch 358/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 64718.7773 - MAE: 62.1902 - val_loss: 68721.9297 - val_MAE: 64.5609\n",
      "Epoch 359/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 64608.7344 - MAE: 62.1410 - val_loss: 68604.8828 - val_MAE: 64.7321\n",
      "Epoch 360/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 64499.9883 - MAE: 62.2471 - val_loss: 68489.8125 - val_MAE: 64.4997\n",
      "Epoch 361/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 64391.5234 - MAE: 62.1862 - val_loss: 68374.3125 - val_MAE: 64.3804\n",
      "Epoch 362/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 64281.2539 - MAE: 62.1117 - val_loss: 68257.6484 - val_MAE: 64.2974\n",
      "Epoch 363/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 64171.8477 - MAE: 62.0016 - val_loss: 68139.1250 - val_MAE: 64.5812\n",
      "Epoch 364/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 64062.2852 - MAE: 62.0703 - val_loss: 68024.4453 - val_MAE: 64.4456\n",
      "Epoch 365/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 63952.5742 - MAE: 61.9560 - val_loss: 67906.6406 - val_MAE: 64.4117\n",
      "Epoch 366/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 63844.2227 - MAE: 62.0772 - val_loss: 67793.7344 - val_MAE: 64.0677\n",
      "Epoch 367/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 63736.4336 - MAE: 62.0357 - val_loss: 67681.0547 - val_MAE: 63.6690\n",
      "Epoch 368/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 63629.5664 - MAE: 61.8148 - val_loss: 67565.8828 - val_MAE: 63.8336\n",
      "Epoch 369/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 63521.0273 - MAE: 61.6512 - val_loss: 67447.4609 - val_MAE: 64.4001\n",
      "Epoch 370/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 63413.5781 - MAE: 61.9546 - val_loss: 67335.7344 - val_MAE: 63.8714\n",
      "Epoch 371/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 63306.1289 - MAE: 61.7683 - val_loss: 67221.3047 - val_MAE: 63.8125\n",
      "Epoch 372/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 63203.8125 - MAE: 61.7617 - val_loss: 67115.2188 - val_MAE: 63.8095\n",
      "Epoch 373/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 63098.9453 - MAE: 61.6691 - val_loss: 67000.0391 - val_MAE: 63.8686\n",
      "Epoch 374/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 62990.8984 - MAE: 61.7718 - val_loss: 66886.1797 - val_MAE: 63.6307\n",
      "Epoch 375/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 62882.9648 - MAE: 61.4838 - val_loss: 66769.7656 - val_MAE: 63.8444\n",
      "Epoch 376/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 62775.8047 - MAE: 61.6735 - val_loss: 66656.2344 - val_MAE: 63.7519\n",
      "Epoch 377/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 62669.1367 - MAE: 61.6085 - val_loss: 66544.1797 - val_MAE: 63.5147\n",
      "Epoch 378/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 62561.5703 - MAE: 61.4949 - val_loss: 66430.1328 - val_MAE: 63.5086\n",
      "Epoch 379/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 62455.6016 - MAE: 61.4359 - val_loss: 66315.9297 - val_MAE: 63.8233\n",
      "Epoch 380/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 62349.8086 - MAE: 61.6112 - val_loss: 66206.4141 - val_MAE: 63.1663\n",
      "Epoch 381/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 62242.9727 - MAE: 61.1924 - val_loss: 66089.1719 - val_MAE: 63.6794\n",
      "Epoch 382/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 62136.4023 - MAE: 61.4847 - val_loss: 65977.6641 - val_MAE: 63.4146\n",
      "Epoch 383/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 62031.1055 - MAE: 61.3250 - val_loss: 65865.4766 - val_MAE: 63.3087\n",
      "Epoch 384/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 12s 4ms/step - loss: 61923.6445 - MAE: 61.2461 - val_loss: 65750.4688 - val_MAE: 63.3266\n",
      "Epoch 385/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 61816.9453 - MAE: 61.2723 - val_loss: 65637.9531 - val_MAE: 63.1875\n",
      "Epoch 386/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 61709.9883 - MAE: 61.0901 - val_loss: 65522.0000 - val_MAE: 63.5177\n",
      "Epoch 387/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 61604.4062 - MAE: 61.2938 - val_loss: 65412.9727 - val_MAE: 63.0295\n",
      "Epoch 388/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 61496.6992 - MAE: 60.8743 - val_loss: 65295.9180 - val_MAE: 63.7654\n",
      "Epoch 389/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 61391.9844 - MAE: 61.1881 - val_loss: 65184.9883 - val_MAE: 63.4171\n",
      "Epoch 390/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 61287.1641 - MAE: 61.1312 - val_loss: 65074.2461 - val_MAE: 63.0929\n",
      "Epoch 391/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 61181.4883 - MAE: 61.0216 - val_loss: 64961.8477 - val_MAE: 63.0240\n",
      "Epoch 392/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 61075.3633 - MAE: 60.9755 - val_loss: 64849.3242 - val_MAE: 62.8837\n",
      "Epoch 393/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 60967.4570 - MAE: 60.8699 - val_loss: 64733.2930 - val_MAE: 63.1427\n",
      "Epoch 394/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 60863.4453 - MAE: 61.1275 - val_loss: 64628.6914 - val_MAE: 62.3506\n",
      "Epoch 395/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 60758.3359 - MAE: 60.8217 - val_loss: 64512.5938 - val_MAE: 62.5843\n",
      "Epoch 396/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 60651.8789 - MAE: 60.7841 - val_loss: 64399.7812 - val_MAE: 62.7399\n",
      "Epoch 397/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 60547.9883 - MAE: 60.8473 - val_loss: 64289.3711 - val_MAE: 62.5158\n",
      "Epoch 398/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 60441.8750 - MAE: 60.4993 - val_loss: 64174.3086 - val_MAE: 63.3509\n",
      "Epoch 399/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 60338.4883 - MAE: 60.9449 - val_loss: 64066.0781 - val_MAE: 62.5767\n",
      "Epoch 400/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 60232.2852 - MAE: 60.6414 - val_loss: 63952.4219 - val_MAE: 62.6174\n",
      "Epoch 401/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 60128.6562 - MAE: 60.6027 - val_loss: 63841.9883 - val_MAE: 62.6982\n",
      "Epoch 402/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 60022.2266 - MAE: 60.5251 - val_loss: 63728.8242 - val_MAE: 62.8002\n",
      "Epoch 403/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 59918.3906 - MAE: 60.4818 - val_loss: 63617.1367 - val_MAE: 63.0636\n",
      "Epoch 404/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 59814.6875 - MAE: 60.6277 - val_loss: 63507.6719 - val_MAE: 62.6164\n",
      "Epoch 405/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 59709.7500 - MAE: 60.4383 - val_loss: 63395.1406 - val_MAE: 62.8599\n",
      "Epoch 406/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 59607.1211 - MAE: 60.5538 - val_loss: 63288.1602 - val_MAE: 62.5016\n",
      "Epoch 407/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 59503.6758 - MAE: 60.5037 - val_loss: 63179.8945 - val_MAE: 62.2027\n",
      "Epoch 408/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 59401.3086 - MAE: 60.3902 - val_loss: 63069.4727 - val_MAE: 62.1530\n",
      "Epoch 409/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 59296.5898 - MAE: 60.4037 - val_loss: 62960.5820 - val_MAE: 61.9375\n",
      "Epoch 410/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 59191.9727 - MAE: 60.2369 - val_loss: 62845.7930 - val_MAE: 62.2279\n",
      "Epoch 411/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 59087.5703 - MAE: 60.2097 - val_loss: 62734.0820 - val_MAE: 62.3897\n",
      "Epoch 412/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 58983.7344 - MAE: 60.2974 - val_loss: 62624.7812 - val_MAE: 62.1971\n",
      "Epoch 413/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 58880.8789 - MAE: 60.1463 - val_loss: 62515.0117 - val_MAE: 62.3006\n",
      "Epoch 414/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 58777.8828 - MAE: 60.1620 - val_loss: 62404.8281 - val_MAE: 62.1718\n",
      "Epoch 415/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 58674.3984 - MAE: 60.1255 - val_loss: 62295.9375 - val_MAE: 62.1050\n",
      "Epoch 416/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 58571.8477 - MAE: 60.0818 - val_loss: 62187.3086 - val_MAE: 62.0409\n",
      "Epoch 417/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 58470.2305 - MAE: 60.2357 - val_loss: 62083.1875 - val_MAE: 61.5154\n",
      "Epoch 418/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 58367.4570 - MAE: 60.0819 - val_loss: 61974.4531 - val_MAE: 61.3319\n",
      "Epoch 419/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 58264.8984 - MAE: 59.8131 - val_loss: 61859.9258 - val_MAE: 61.7897\n",
      "Epoch 420/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 58160.3906 - MAE: 60.0072 - val_loss: 61750.5195 - val_MAE: 61.6203\n",
      "Epoch 421/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 58056.0312 - MAE: 59.8159 - val_loss: 61640.3516 - val_MAE: 61.8663\n",
      "Epoch 422/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 57956.1914 - MAE: 59.8067 - val_loss: 61532.7617 - val_MAE: 62.0343\n",
      "Epoch 423/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 57855.6016 - MAE: 59.9008 - val_loss: 61424.9531 - val_MAE: 61.8135\n",
      "Epoch 424/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 57753.6094 - MAE: 59.9463 - val_loss: 61320.7852 - val_MAE: 61.3084\n",
      "Epoch 425/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 57652.2148 - MAE: 59.6759 - val_loss: 61209.3086 - val_MAE: 61.5950\n",
      "Epoch 426/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 57549.9297 - MAE: 59.6432 - val_loss: 61101.5469 - val_MAE: 61.7463\n",
      "Epoch 427/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 57449.8789 - MAE: 59.6496 - val_loss: 60992.8867 - val_MAE: 61.8399\n",
      "Epoch 428/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 57349.0352 - MAE: 59.7612 - val_loss: 60886.5820 - val_MAE: 61.6078\n",
      "Epoch 429/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 57246.0273 - MAE: 59.5768 - val_loss: 60775.6562 - val_MAE: 61.7852\n",
      "Epoch 430/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 57145.2969 - MAE: 59.6863 - val_loss: 60670.5547 - val_MAE: 61.5072\n",
      "Epoch 431/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 57044.5195 - MAE: 59.5780 - val_loss: 60563.2461 - val_MAE: 61.3975\n",
      "Epoch 432/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 56942.2461 - MAE: 59.5040 - val_loss: 60453.6875 - val_MAE: 61.3434\n",
      "Epoch 433/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 56840.0469 - MAE: 59.6307 - val_loss: 60349.4805 - val_MAE: 60.9202\n",
      "Epoch 434/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 56738.8828 - MAE: 59.4137 - val_loss: 60241.1211 - val_MAE: 60.9169\n",
      "Epoch 435/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 56637.0742 - MAE: 59.2221 - val_loss: 60128.9688 - val_MAE: 61.4657\n",
      "Epoch 436/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 56536.5195 - MAE: 59.4004 - val_loss: 60020.8320 - val_MAE: 61.5996\n",
      "Epoch 437/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 56434.5547 - MAE: 59.4797 - val_loss: 59914.7695 - val_MAE: 61.0688\n",
      "Epoch 438/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 56332.8047 - MAE: 59.2611 - val_loss: 59804.8555 - val_MAE: 61.1319\n",
      "Epoch 439/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 12s 4ms/step - loss: 56229.4922 - MAE: 59.1108 - val_loss: 59694.1992 - val_MAE: 61.6223\n",
      "Epoch 440/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 56128.8203 - MAE: 59.3655 - val_loss: 59589.6562 - val_MAE: 61.0903\n",
      "Epoch 441/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 56029.4766 - MAE: 59.1288 - val_loss: 59482.9805 - val_MAE: 61.1702\n",
      "Epoch 442/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 55929.1758 - MAE: 59.2346 - val_loss: 59377.7773 - val_MAE: 60.8821\n",
      "Epoch 443/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 55828.1367 - MAE: 59.1692 - val_loss: 59269.4961 - val_MAE: 60.8876\n",
      "Epoch 444/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 55727.7148 - MAE: 59.1238 - val_loss: 59165.3672 - val_MAE: 60.6717\n",
      "Epoch 445/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 55627.5391 - MAE: 58.9076 - val_loss: 59054.9688 - val_MAE: 61.1259\n",
      "Epoch 446/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 55527.0039 - MAE: 59.0965 - val_loss: 58949.4414 - val_MAE: 60.8230\n",
      "Epoch 447/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 55426.6641 - MAE: 58.7737 - val_loss: 58841.3711 - val_MAE: 61.4202\n",
      "Epoch 448/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 55325.8125 - MAE: 58.9277 - val_loss: 58732.5859 - val_MAE: 61.4084\n",
      "Epoch 449/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 55225.6133 - MAE: 59.0961 - val_loss: 58629.7305 - val_MAE: 60.6101\n",
      "Epoch 450/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 55125.1680 - MAE: 58.7113 - val_loss: 58520.4375 - val_MAE: 61.1607\n",
      "Epoch 451/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 55025.9219 - MAE: 58.7793 - val_loss: 58414.9844 - val_MAE: 61.1912\n",
      "Epoch 452/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 54928.2148 - MAE: 59.0090 - val_loss: 58313.5703 - val_MAE: 60.4784\n",
      "Epoch 453/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 54828.5078 - MAE: 58.7812 - val_loss: 58207.6250 - val_MAE: 60.3937\n",
      "Epoch 454/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 54729.1133 - MAE: 58.6025 - val_loss: 58099.0312 - val_MAE: 60.8170\n",
      "Epoch 455/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 54628.5234 - MAE: 58.7238 - val_loss: 57992.7852 - val_MAE: 60.6173\n",
      "Epoch 456/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 54528.9219 - MAE: 58.6593 - val_loss: 57887.8008 - val_MAE: 60.4958\n",
      "Epoch 457/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 54430.1445 - MAE: 58.7511 - val_loss: 57786.4727 - val_MAE: 60.0219\n",
      "Epoch 458/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 54329.9922 - MAE: 58.3273 - val_loss: 57674.0156 - val_MAE: 60.9261\n",
      "Epoch 459/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 54231.3047 - MAE: 58.8429 - val_loss: 57575.2422 - val_MAE: 59.9208\n",
      "Epoch 460/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 54132.2227 - MAE: 58.3804 - val_loss: 57464.6523 - val_MAE: 60.4165\n",
      "Epoch 461/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 54032.4688 - MAE: 58.5005 - val_loss: 57359.7422 - val_MAE: 60.2452\n",
      "Epoch 462/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 53933.7500 - MAE: 58.3789 - val_loss: 57253.7930 - val_MAE: 60.5468\n",
      "Epoch 463/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 53836.0859 - MAE: 58.4478 - val_loss: 57150.0234 - val_MAE: 60.3801\n",
      "Epoch 464/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 53736.6523 - MAE: 58.2229 - val_loss: 57043.5664 - val_MAE: 60.8163\n",
      "Epoch 465/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 53639.3672 - MAE: 58.5909 - val_loss: 56944.3750 - val_MAE: 59.9161\n",
      "Epoch 466/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 53540.4336 - MAE: 58.1584 - val_loss: 56833.8164 - val_MAE: 60.4053\n",
      "Epoch 467/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 53441.3984 - MAE: 58.3156 - val_loss: 56730.5703 - val_MAE: 60.3102\n",
      "Epoch 468/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 53344.4336 - MAE: 58.2064 - val_loss: 56626.7500 - val_MAE: 60.3429\n",
      "Epoch 469/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 53246.6211 - MAE: 58.2446 - val_loss: 56523.0273 - val_MAE: 60.1250\n",
      "Epoch 470/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 53148.5586 - MAE: 58.2457 - val_loss: 56420.0625 - val_MAE: 59.8576\n",
      "Epoch 471/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 53050.6562 - MAE: 58.1900 - val_loss: 56318.4102 - val_MAE: 59.6302\n",
      "Epoch 472/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 52952.9219 - MAE: 58.0209 - val_loss: 56210.8203 - val_MAE: 59.8750\n",
      "Epoch 473/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 52854.5391 - MAE: 58.1885 - val_loss: 56112.2930 - val_MAE: 59.3926\n",
      "Epoch 474/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 52758.2930 - MAE: 57.9245 - val_loss: 56005.5117 - val_MAE: 59.6927\n",
      "Epoch 475/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 52661.0469 - MAE: 57.9784 - val_loss: 55901.8242 - val_MAE: 59.8559\n",
      "Epoch 476/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 52565.4609 - MAE: 58.1633 - val_loss: 55806.9570 - val_MAE: 59.1054\n",
      "Epoch 477/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 52469.1367 - MAE: 57.7585 - val_loss: 55695.8281 - val_MAE: 59.6157\n",
      "Epoch 478/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 52368.5352 - MAE: 57.7115 - val_loss: 55588.6719 - val_MAE: 60.0629\n",
      "Epoch 479/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 52272.0898 - MAE: 57.9026 - val_loss: 55486.9844 - val_MAE: 59.8034\n",
      "Epoch 480/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 52175.4531 - MAE: 57.9543 - val_loss: 55385.9062 - val_MAE: 59.4496\n",
      "Epoch 481/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 52078.6992 - MAE: 57.7130 - val_loss: 55282.3281 - val_MAE: 59.6094\n",
      "Epoch 482/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51982.4180 - MAE: 57.7159 - val_loss: 55178.8438 - val_MAE: 59.6958\n",
      "Epoch 483/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51885.3516 - MAE: 57.6525 - val_loss: 55075.2148 - val_MAE: 59.8245\n",
      "Epoch 484/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51788.5039 - MAE: 57.8022 - val_loss: 54973.5156 - val_MAE: 59.3383\n",
      "Epoch 485/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51690.5547 - MAE: 57.7613 - val_loss: 54871.5977 - val_MAE: 59.1317\n",
      "Epoch 486/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51594.3047 - MAE: 57.4530 - val_loss: 54765.8281 - val_MAE: 59.5329\n",
      "Epoch 487/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51497.4766 - MAE: 57.5944 - val_loss: 54663.2656 - val_MAE: 59.5243\n",
      "Epoch 488/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51400.4375 - MAE: 57.4837 - val_loss: 54559.1836 - val_MAE: 59.6807\n",
      "Epoch 489/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51304.6953 - MAE: 57.5367 - val_loss: 54458.0156 - val_MAE: 59.4608\n",
      "Epoch 490/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51208.7070 - MAE: 57.3774 - val_loss: 54355.6328 - val_MAE: 59.6639\n",
      "Epoch 491/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51114.3594 - MAE: 57.5218 - val_loss: 54255.9062 - val_MAE: 59.3680\n",
      "Epoch 492/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 51018.8555 - MAE: 57.4023 - val_loss: 54154.3984 - val_MAE: 59.2931\n",
      "Epoch 493/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 50923.8984 - MAE: 57.4561 - val_loss: 54055.2891 - val_MAE: 59.0170\n",
      "Epoch 494/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 12s 4ms/step - loss: 50828.1992 - MAE: 57.4675 - val_loss: 53956.2969 - val_MAE: 58.6706\n",
      "Epoch 495/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 50733.0312 - MAE: 57.1186 - val_loss: 53849.6484 - val_MAE: 59.1546\n",
      "Epoch 496/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 50637.1289 - MAE: 57.2895 - val_loss: 53748.9766 - val_MAE: 59.0338\n",
      "Epoch 497/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 50542.1992 - MAE: 57.2429 - val_loss: 53648.6641 - val_MAE: 58.9583\n",
      "Epoch 498/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 50447.7227 - MAE: 57.1844 - val_loss: 53547.6211 - val_MAE: 58.9040\n",
      "Epoch 499/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 50353.5781 - MAE: 57.1214 - val_loss: 53447.5547 - val_MAE: 58.9778\n",
      "Epoch 500/500\n",
      "2768/2768 [==============================] - 12s 4ms/step - loss: 50256.7188 - MAE: 56.9485 - val_loss: 53343.8906 - val_MAE: 59.7952\n",
      "INFO:tensorflow:Assets written to: mansur/experiment_10/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 03:59:44.054636: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "csv_logger = CSVLogger(f'{work_dir}/training.log', append=True)\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=f'{work_dir}/checkpoint/weights',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_MAE',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs = 500,\n",
    "    initial_epoch=0,\n",
    "    validation_split=.2,\n",
    "    callbacks=[csv_logger, model_checkpoint_callback],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "model.save(f'{work_dir}/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8ee554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865/865 [==============================] - 3s 3ms/step - loss: 49256.3008 - MAE: 56.8920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[49256.30078125, 56.89198684692383]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02533c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
