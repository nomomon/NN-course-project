In this section we will analyze our results, reflect on the development process and talk about what worked best and finally talk about some improvements that could have been made to our project.


\subsection{Analysis}

The aim of this project was to train a MLP to learn to predict the energy of a molecule, which was done successfully. Our model predicts energy of bigger molecules with an error of $\pm 1$ kJ and smaller ones with $\pm 3$ kJ, which is good. This difference could be the result of the dataset being unevenly distributed, favouring bigger molecules as seen in \ref{fig:distribution-of-data}. However, this should not and did not effect the results a in a fundamentally important way because the final energy of the molecule is not dependent on the size but rather the energies in the bonds. It could be that the model trained on the bigger molecules attributed bigger and smaller energies to each covalent bond and while it cancels out in the bigger molecules, the difference is observable in the small ones.

The model's accuracy is overall fairly reasonable. It gives potential energy levels close to the actual values of the molecules, independent of the size of the molecule. However, these values may not be sufficiently precise for all purposes. If one is to find wider applications for the learning algorithm as described in this report, this needs to be resolved. One potential reason behind the imprecision could be because of how the bond order matrices are made, and addressed in the improvements section.

\subsection{Reflection}
In the process of designing an algorithm that could estimate the potential energy of a molecule, the main challenge did not necessarily lie in determining the optimal structure of the neural network itself. We settled on creating a MLP by means of predefined python libraries relatively quickly. The most challenging part of the entire process was figuring out how to do the data preprocessing to achieve the best results. More specifically, we underestimated the complexity in the spatial configuration of the atoms in the molecules and first few attempts in preproccessing the data resulted in losing the features that were important for the model. For example the realization that the bond order is a crucial determinant of the energy level in said covalent bond, did not come until relatively late in the project. 

\subsection{Improvements and Future Directions}

To improve this project, rather than using a MLP, we propose using graph neural networks (GNN). Molecules posses a graph like structure as pointed out before. Therefore it naturally makes intuitive sense to implement the learning algorithm by means of a GNN. Furthermore, current research has discovered that GNN's show promising results for predicting molecular properties including potential energy \cite{gnn1, gnn2}. Although we thought about implementing one from the beginning, it is unfortunately outside the scope of this report. 

Improvements could also be made in the preprocessing pipeline. Specifically, the process of figuring out the bond orders can be optimized. As we saw in the section \ref{sec:bond-orders}, not all the molecules had a bond matrix that resulted in a solution from the CSP, which was fixed manually by hand. However, we do not know if  there are molecules that got a solution from an incorrect bond matrix. These little mistakes maybe do not effect the overall accuracy, but effect the precision of the model. Hence, we invite readers to think about how to find the bond matrix differently (more accurately) or the bond order matrix in general.

During the work on this project we found another way, besides using a CSP, to find the bond orders. We used the mean distance of each type of covalent bond. In other words, if the two atoms are within a certain distance so that they form a covalent bond of some order, then they are bonded as such. This method gave us a MAE of $\pm0.03$ for all the molecules. However, the problem with this method is that it does not account for the octet rule or chemistry theory in any way. And we could not motivate the choices we made.